# -*- coding: utf-8 -*-
import streamlit as st
import time
from utils.intel_manager import get_claims, add_claims, delete_claim, mark_claims_distinct
from utils.ai_parser import parse_metaso_report, find_duplicate_candidates
from utils.researcher import ask_metaso_research_loop
from utils.researcher import ask_metaso_research_loop
from utils.config import load_config
from utils.data_fetcher import get_stock_news_raw
from utils.intelligence_processor import summarize_intelligence
from utils.qwen_agent import search_with_qwen

def render_intel_hub(code: str, name: str, price: float, avg_cost: float, shares_held: int, strat_res: dict, total_capital: float, current_alloc: float):
    """
    æ¸²æŸ“è‚¡ç¥¨æƒ…æŠ¥æ•°æ®åº“ç»„ä»¶ (Intelligence Hub)
    """
    settings = load_config().get("settings", {})
    metaso_api_key = st.session_state.get("input_metaso_key", "")
    deepseek_api_key = st.session_state.get("input_apikey", "")
    metaso_base_url = settings.get("metaso_base_url", "https://metaso.cn/api/v1")
    
    with st.expander("ğŸ—ƒï¸ è‚¡ç¥¨æƒ…æŠ¥æ•°æ®åº“ (Intelligence Hub)", expanded=False):
        # --- Top Action Buttons ---
        col_top1, col_top2, col_top3 = st.columns([0.33, 0.33, 0.33])

        
        # 1. Metaso Search Button
        if col_top1.button("ğŸ” ç§˜å¡”æ·±åº¦æœç´¢", key=f"btn_metaso_{code}", use_container_width=True):
            if not metaso_api_key or not deepseek_api_key:
                st.warning("è¯·åœ¨ä¾§è¾¹æ è®¾ç½® Metaso API Key å’Œ DeepSeek API Key")
            else:
                with st.spinner(f"ğŸ” ç§˜å¡”æ­£åœ¨æ£€ç´¢ {name} çš„æœ€æ–°æƒ…æŠ¥..."):
                    prompts = load_config().get("prompts", {})
                    context = {
                        "code": code, "name": name, "price": price, "cost": avg_cost, 
                        "current_shares": shares_held, "support": strat_res.get('support'), 
                        "resistance": strat_res.get('resistance'), "signal": strat_res.get('signal'),
                        "reason": strat_res.get('reason'), "capital_allocation": current_alloc,
                        "total_capital": total_capital
                    }
                    
                    research_report = ask_metaso_research_loop(
                        metaso_api_key, metaso_base_url, deepseek_api_key, context, 
                        base_query_template=prompts.get("metaso_query", ""),
                        existing_claims=get_claims(code),
                        metaso_parser_template=prompts.get("metaso_parser", "")
                    )
                    
                    # Manual Parse call (ask_metaso_research_loop usually returns raw text, we parse it)
                    # Note: ask_metaso_research_loop inside researcher.py MIGHT already parse? 
                    # Let's check imports. In main.py it calls ask_metaso_research_loop THEN parse_metaso_report.
                    # Yes.
                    
                    parse_res = parse_metaso_report(deepseek_api_key, research_report, get_claims(code), prompt_template=prompts.get("metaso_parser", ""))
                    if parse_res.get("new_claims"): 
                        add_claims(code, parse_res["new_claims"])
                        st.success(f"æˆåŠŸæ”¶é›†åˆ° {len(parse_res['new_claims'])} æ¡æ–°æƒ…æŠ¥ï¼")
                    else:
                        st.info("æœªå‘ç°æ˜¾è‘—çš„æ–°å¢æƒ…æŠ¥ã€‚")
                    time.sleep(1)
                    st.rerun()

        # 2. Qwen Search Button [NEW]
        if col_top2.button("ğŸ¶ Qwen å…¨ç½‘æ£€ç´¢", key=f"btn_qwen_{code}", use_container_width=True):
            if not deepseek_api_key and not settings.get("qwen_api_key"): 
                st.warning("è¯·è®¾ç½® Qwen API Key (DashScope)")
            else:
                 # Try to get DashScope key specifically if separate, or use same one
                dashscope_key = settings.get("dashscope_api_key") or settings.get("qwen_api_key") or deepseek_api_key
                
                with st.spinner(f"ğŸ¶ Qwen æ­£åœ¨å…¨ç½‘æ£€ç´¢ {name} ..."):
                     # Construct query
                    query = f"Aè‚¡ {name} ({code}) æœ€æ–°é‡å¤§åˆ©å¥½ä¸åˆ©ç©ºæ¶ˆæ¯ ä¸šç»© ç ”æŠ¥"
                    
                    new_claims = search_with_qwen(dashscope_key, query)
                    if new_claims:
                        add_claims(code, new_claims, source="Qwen Search")
                        st.success(f"Qwen æœå¯»åˆ° {len(new_claims)} æ¡æ–°æƒ…æŠ¥ï¼")
                    else:
                        st.warning("Qwen æœªæœå¯»åˆ°æœ‰æ•ˆæƒ…æŠ¥æˆ–æ¥å£å¼‚å¸¸ã€‚")
                    time.sleep(1)
                    st.rerun()

        # 3. Dedupe Button
        if f"dedupe_results_{code}" not in st.session_state:
            st.session_state[f"dedupe_results_{code}"] = None
        
        current_claims = get_claims(code)
        if col_top3.button("ğŸ§¹ æ‰«æé‡å¤å¹¶æ¸…ç†", key=f"btn_dedupe_{code}", use_container_width=True):
            if not current_claims:
                st.info("æš‚æ— æƒ…æŠ¥å¯ä¾›æ¸…ç†")
            else:
                with st.spinner("æ­£åœ¨å¯¹æ¯”è¯­ä¹‰åˆ†æé‡å¤é¡¹ (DeepSeek)..."):
                    if not deepseek_api_key:
                        st.error("è¯·å…ˆè®¾ç½® DeepSeek API Key")
                    else:
                        dupe_groups = find_duplicate_candidates(deepseek_api_key, current_claims)
                        if not dupe_groups:
                            st.success("æœªå‘ç°é‡å¤æƒ…æŠ¥ï¼")
                            st.session_state[f"dedupe_results_{code}"] = None
                        else:
                            st.session_state[f"dedupe_results_{code}"] = dupe_groups
                            st.rerun()

        # --- Dedupe Review Interface (Top) ---
        dupe_groups = st.session_state.get(f"dedupe_results_{code}")
        if dupe_groups:
            st.warning(f"âš ï¸ å‘ç° {len(dupe_groups)} ç»„é‡å¤æƒ…æŠ¥ï¼Œè¯·ç¡®è®¤åˆå¹¶æ“ä½œï¼š")
            for g_idx, group in enumerate(dupe_groups):
                with st.container(border=True):
                    st.caption(f"é‡å¤ç»„ #{g_idx+1} (åŸå› : {group['reason']})")
                    items = group['items']
                    rec_id = group.get('recommended_keep')
                    cols = st.columns(len(items))
                    for i, item_obj in enumerate(items):
                        is_rec = (item_obj['id'] == rec_id)
                        with cols[i]:
                            box_color = "green" if is_rec else "grey"
                            st.markdown(f":{box_color}[**ID: {item_obj['id']}**]")
                            if is_rec: st.caption("âœ¨ å»ºè®®ä¿ç•™")
                            st.text_area("å†…å®¹", item_obj['content'], height=250, disabled=True, key=f"txt_{code}_{g_idx}_{item_obj['id']}")
                            if st.button(f"âœ… ä¿ç•™æ­¤æ¡ (åˆå¹¶)", key=f"keep_{code}_{g_idx}_{item_obj['id']}"):
                                others = [x['id'] for x in items if x['id'] != item_obj['id']]
                                for oid in others: delete_claim(code, oid)
                                st.toast(f"âœ… å·²åˆå¹¶ï¼Œä¿ç•™äº† ID: {item_obj['id']}")
                                current_groups = st.session_state.get(f"dedupe_results_{code}", [])
                                if g_idx < len(current_groups):
                                    current_groups.pop(g_idx)
                                    st.session_state[f"dedupe_results_{code}"] = current_groups
                                time.sleep(1)
                                st.rerun()
                    if st.button(f"å¿½ç•¥æ­¤ç»„", key=f"ignore_{g_idx}_{code}"):
                        group_ids = [str(x['id']) for x in items]
                        mark_claims_distinct(code, group_ids)
                        current_groups = st.session_state.get(f"dedupe_results_{code}", [])
                        if g_idx < len(current_groups):
                            current_groups.pop(g_idx)
                            st.session_state[f"dedupe_results_{code}"] = current_groups
                        st.rerun()
        
        st.markdown("---")
        
        # [NEW] Manual Input Section
        with st.expander("ğŸ“ æ‰‹åŠ¨å½•å…¥é‡è¦æƒ…æŠ¥ (Manual Input)", expanded=True):
            user_intel = st.text_area(
                "è¯·è¾“å…¥æ‚¨è·å¾—çš„æƒ…æŠ¥ (å°†ä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§ä¼ ç»™AI):", 
                height=100, 
                key=f"manual_intel_{code}",
                help="æ­¤å¤„è¾“å…¥çš„ä¿¡æ¯ä¼šè¢«æ ‡è®°ä¸ºã€UserManualã€‘æ¥æºï¼Œå¹¶åœ¨DeepSeekæç¤ºè¯ä¸­ç½®é¡¶æ˜¾ç¤ºã€‚"
            )
            if st.button("ğŸ’¾ ä¿å­˜æƒ…æŠ¥", key=f"btn_save_manual_{code}"):
                if not user_intel.strip():
                    st.warning("å†…å®¹ä¸èƒ½ä¸ºç©º")
                else:
                    add_claims(code, [user_intel.strip()], source="UserManual")
                    st.success("å·²ä¿å­˜ï¼è¯¥æƒ…æŠ¥å°†ä½œä¸ºæ ¸å¿ƒä¿¡æ¯ä¼ ç»™AIã€‚")
                    time.sleep(1)
                    st.rerun()


        st.markdown("---")
        
        # [NEW] Real-time News Section (EastMoney)
        with st.expander("ğŸŒ å®æ—¶èµ„è®¯ (EastMoney/Sina)", expanded=False):
            n_col1, n_col2 = st.columns([0.3, 0.7])
            with n_col1:
                if st.button("ğŸ”„ åˆ·æ–°èµ„è®¯", key=f"btn_refresh_news_{code}"):
                    get_stock_news_raw.clear()
                    st.toast("å·²æ¸…é™¤èµ„è®¯ç¼“å­˜ï¼Œæ­£åœ¨é‡æ–°æŠ“å–...")
                    time.sleep(0.5)
                    st.rerun()
            with n_col2:
                if st.button("âš¡ AI æç‚¼å…¥åº“ (Summarize & Save)", key=f"btn_sum_news_{code}", help="è°ƒç”¨ DeepSeek é˜…è¯»æœ€æ–°20æ¡æ–°é—»ï¼Œç”Ÿæˆæ‘˜è¦å¹¶å­˜å…¥æƒ…æŠ¥åº“"):
                    if not deepseek_api_key:
                        st.error("è¯·å…ˆè®¾ç½® DeepSeek API Key")
                    else:
                        with st.spinner("ğŸ¤– æ­£åœ¨é˜…è¯»å¹¶æç‚¼æœ€è¿‘20æ¡æ–°é—»..."):
                            try:
                                raw_news = get_stock_news_raw(code, n=20)
                                if raw_news:
                                    summary = summarize_intelligence(deepseek_api_key, raw_news, name)
                                    if summary:
                                        # Save as a single consolidated claim
                                        add_claims(code, [summary], source="EastMoney AIæ‘˜è¦")
                                        st.success("âœ… å·²æç‚¼å¹¶å­˜å…¥æƒ…æŠ¥åº“ï¼")
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        st.warning("AI æœªç”Ÿæˆæœ‰æ•ˆæ‘˜è¦")
                                else:
                                    st.warning("æ— æ–°é—»å¯æç‚¼")
                            except Exception as e:
                                st.error(f"æç‚¼å¤±è´¥: {e}")
                
            try:
                news_items = get_stock_news_raw(code, n=10)
                if not news_items:
                    st.info("æš‚æ— æœ€æ–°èµ„è®¯ã€‚")
                else:
                    for news in news_items:
                        n_title = news.get("title", "æ— æ ‡é¢˜")
                        n_date = news.get("date", "")
                        n_url = news.get("url", "")
                        
                        # Format
                        st.markdown(f"**[{n_date}]** [{n_title}]({n_url})")
            except Exception as e:
                st.error(f"èµ„è®¯è·å–å¤±è´¥: {e}")

        st.markdown("---")
        st.markdown("---")
        current_claims = get_claims(code)
        if not current_claims:
            st.info("æš‚æ— æ”¶å›çš„æƒ…æŠ¥ã€‚è¯·ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è¿›è¡ŒæŠ“å–ã€‚")
        else:
            # Group claims by source
            manual_claims = []
            ai_claims = []
            search_claims = []
            
            for item in current_claims:
                source = item.get('source', '')
                if source == 'UserManual':
                    manual_claims.append(item)
                elif source == 'EastMoney AIæ‘˜è¦':
                    ai_claims.append(item)
                else:
                    search_claims.append(item)
            
            # Create Tabs
            tab_u, tab_a, tab_s = st.tabs([
                f"ğŸš¨ æ ¸å¿ƒæƒ…æŠ¥ ({len(manual_claims)})", 
                f"ğŸ¤– AI ç ”æŠ¥ ({len(ai_claims)})", 
                f"ğŸ” æ·±åº¦æœç´¢ ({len(search_claims)})"
            ])
            
            def render_claim_item(item):
                status_map = {
                    "verified": "ğŸŸ¢",
                    "disputed": "ğŸŸ ",
                    "false_info": "âŒ",
                    "pending": "âšª"
                }
                status_icon = status_map.get(item.get('status', 'pending'), "âšª")
                
                # Special icon for manual
                src = item.get('source', '')
                if src == 'UserManual':
                    status_icon = "ğŸš¨"
                elif src == 'Qwen Search':
                     status_icon = "ğŸ¶"
                elif src == 'Metaso':
                     status_icon = "â“‚ï¸"

                content_display = item['content']
                if item.get('status') == 'false_info':
                    content_display = f"~~{content_display}~~ (å·²è¯ä¼ª)"
                
                with st.container(border=True):
                    col_main, col_del = st.columns([0.9, 0.1])
                    with col_main:
                        st.markdown(f"**{status_icon} [{item['timestamp']}]**")
                        st.caption(f"æ¥æº: {src}")
                        st.code(content_display, language=None, wrap_lines=True)
                        if item.get('note'):
                            st.info(f"å¤‡æ³¨: {item['note']}")
                    with col_del:
                        if st.button("ğŸ—‘ï¸", key=f"del_{item['id']}", help="åˆ é™¤æ­¤æ¡æƒ…æŠ¥"):
                            delete_claim(code, item['id'])
                            st.rerun()

            with tab_u:
                if manual_claims:
                    for item in manual_claims:
                        render_claim_item(item)
                else:
                    st.info("æš‚æ— ç”¨æˆ·å½•å…¥çš„æ ¸å¿ƒæƒ…æŠ¥")

            with tab_a:
                if ai_claims:
                    for item in ai_claims:
                        render_claim_item(item)
                else:
                    st.info("æš‚æ—  AI ç”Ÿæˆçš„ç ”æŠ¥æ‘˜è¦")

            with tab_s:
                if search_claims:
                    for item in search_claims:
                        render_claim_item(item)
                else:
                    st.info("æš‚æ— æ·±åº¦æœç´¢æƒ…æŠ¥")
