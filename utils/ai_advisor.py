import requests
import json
import pandas as pd
from datetime import datetime

from google import genai
from utils.storage import load_production_log
from utils.data_fetcher import calculate_price_limits
from utils.database import db_get_history
from utils.time_utils import get_beijing_time, get_market_session, get_next_trading_day, is_trading_day

def build_advisor_prompt(context_data, research_context="", technical_indicators=None, fund_flow_data=None, fund_flow_history=None, intraday_summary=None, prompt_templates=None, suffix_key="proposer_premarket_suffix", symbol=None):
    """
    Constructs the System Prompt and User Prompt for the AI Advisor.
    Returns: (system_prompt, user_prompt)
    """
    if not prompt_templates: prompt_templates = {}
    
    base_tpl = prompt_templates.get("proposer_base", "")
    suffix_tpl = prompt_templates.get(suffix_key, "")
    simple_suffix_tpl = prompt_templates.get("proposer_simple_suffix", "")
    
    if not base_tpl:
        return "", "Error: Prompt templates missing."

    # [Logic] Phase Determination based on Time (Centralized in time_utils)
    now = get_beijing_time()
    session = get_market_session()
    
    if session == "closed":
        # Post-market logic: Determine if we should show Next Trading Day
        # If it's a trading day and after 15:00, or a weekend
        target_date = get_next_trading_day(now.date())
        context_data['date'] = f"{target_date.strftime('%Y-%m-%d')} (ä¸‹ä¸ªäº¤æ˜“æ—¥)"
        context_data['market_status'] = "CLOSED_POST"
    elif session == "morning_break":
        context_data['market_status'] = "CLOSED_NOON"
    elif session == "pre_market":
        context_data['market_status'] = "PRE_OPEN"
    else:
        # trading (Intraday)
        context_data['market_status'] = "OPEN_INTRADAY"
        if is_trading_day(now.date()):
             research_context += "\nã€âš ï¸ æç¤ºã€‘: å½“å‰å¤„äºåŒ—äº¬æ—¶é—´ç›˜ä¸­äº¤æ˜“æ—¶æ®µï¼Œå»ºè®®ä»¥è§‚å¯Ÿä¸ºä¸»ï¼Œå¾…åˆé—´æˆ–ç›˜åå†è¿›è¡Œæ­£å¼ç­–ç•¥ä¿®å®šã€‚"

    # 2. Format Base
    # Calculate Price Limits
    if 'code' in context_data:
         # [Business Logic] Base Price Selection for Limit Calculation
         m_status = context_data.get('market_status')
         
         if m_status == "CLOSED_POST":
             # Post-market: Forecasting for NEXT Day, use Today's Close as base
             limit_base = float(context_data.get('price', 0))
         else:
             # Pre-market or Noon-market: Working with TODAY's limits, use Yesterday's Close as base
             # Even if 'limit_base_price' is passed from UI, we override it for correctness in NOON mode
             limit_base = float(context_data.get('pre_close', 0))
             
         if limit_base == 0: 
             limit_base = float(context_data.get('price', 0))
         
         l_up, l_down = calculate_price_limits(
             context_data.get('code', ''),
             context_data.get('name', ''),
             limit_base
         )
         context_data['limit_up'] = l_up
         context_data['limit_down'] = l_down
    else:
         context_data['limit_up'] = "N/A"
         context_data['limit_down'] = "N/A"

    try:
        base_prompt = base_tpl.format(**context_data)
    except KeyError as e:
        base_prompt = f"Prompt Error: Missing key {e}"

    # 3. Append Suffix
    if isinstance(technical_indicators, dict) and suffix_tpl:
        # Prepare data for suffix
        
        # Format Fund Flow
        capital_flow_str = "N/A"
        if fund_flow_data and not fund_flow_data.get("error"):
            flow_lines = [f"{k}: {v}" for k, v in fund_flow_data.items()]
            fund_lines = [" | ".join(flow_lines)]
        elif fund_flow_data and fund_flow_data.get("error"):
            fund_lines = [f"å½“æ—¥æ•°æ®è·å–å¤±è´¥: {fund_flow_data.get('error')}"]
        else:
            fund_lines = []

        # Format History Fund Flow
        if fund_flow_history is not None and not fund_flow_history.empty:
            try:
                recent = fund_flow_history.tail(20)
                table_lines = ["\n**è¿‘20äº¤æ˜“æ—¥èµ„é‡‘æµå‘è¶‹åŠ¿:**", "| æ—¥æœŸ | æ”¶ç›˜ | æ¶¨è·Œ% | ä¸»åŠ›å‡€æµå…¥(ä¸‡) | è¶…å¤§å•(ä¸‡) | å¤§å•(ä¸‡) |", "|---|---|---|---|---|---|"]
                
                total_main_flow = 0.0
                positive_flow_days = 0
                total_days = len(recent)

                for _, row in recent.iterrows():
                    d = row['æ—¥æœŸ'].strftime('%m-%d') if hasattr(row['æ—¥æœŸ'], 'strftime') else str(row['æ—¥æœŸ'])[:10]
                    c = row.get('æ”¶ç›˜ä»·', 0)
                    p = row.get('æ¶¨è·Œå¹…', 0)
                    if pd.isna(p): p = 0
                    
                    raw_main = row.get('ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0)
                    if not pd.isna(raw_main):
                        total_main_flow += float(raw_main)
                        if float(raw_main) > 0:
                            positive_flow_days += 1

                    def to_wan(v):
                        try:
                            if pd.isna(v): return "0"
                            return f"{float(v)/10000:.0f}"
                        except:
                            return str(v)
                            
                    m_flow = to_wan(row.get('ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0))
                    s_flow = to_wan(row.get('è¶…å¤§å•å‡€æµå…¥-å‡€é¢', 0))
                    b_flow = to_wan(row.get('å¤§å•å‡€æµå…¥-å‡€é¢', 0))
                    
                    table_lines.append(f"| {d} | {c} | {p:.2f} | {m_flow} | {s_flow} | {b_flow} |")
                
                fund_lines.append("\n".join(table_lines))
                
                flow_trend = "æµå…¥" if total_main_flow > 0 else "æµå‡º"
                summary_line = (
                    f"\nã€èµ„é‡‘ç»Ÿè®¡ã€‘è¿‘{total_days}æ—¥ä¸»åŠ›ç´¯è®¡å‡€{flow_trend} {abs(total_main_flow)/10000:.1f}ä¸‡ã€‚ "
                    f"å…¶ä¸­ {positive_flow_days} å¤©ä¸ºå‡€æµå…¥ï¼ˆå æ¯” {positive_flow_days/total_days:.0%}ï¼‰ã€‚"
                )
                fund_lines.append(summary_line)

            except Exception as e:
                fund_lines.append(f"\n(å†å²æ•°æ®æ ¼å¼åŒ–é”™è¯¯: {e})")
        
        capital_flow_str = "\n".join(fund_lines) if fund_lines else "N/A"
        
        # Format RAG Context (History + Execution)
        # 1. Start with Intelligence (Most Important for Decision)
        final_research_context = ""
        if research_context and len(research_context.strip()) > 0:
            final_research_context = f"\n[æ ¸å¿ƒæƒ…æŠ¥åº“ (Market Intelligence & Search Context)]:\n{research_context}"
        else:
            final_research_context = "\n[æ ¸å¿ƒæƒ…æŠ¥åº“]: (æš‚æ— å¤–éƒ¨æ•æ„Ÿä¿¡å·)"
        
        if symbol:
            try:
                # 1. ALWAYS Load Trades (Even if no AI history exists)
                all_trades = db_get_history(symbol)
                valid_types = ['buy', 'sell']
                real_trades = []
                for t in all_trades:
                    t_type = str(t.get('type', '')).strip().lower()
                    if (t_type in valid_types or 'override' in t_type) and t.get('amount', 0) > 0:
                        t['type'] = t_type 
                        real_trades.append(t)
                
                # 1b. [Digital Twin v4.0] Dedicated Recent Execution Registry
                if real_trades:
                    exec_lines = ["\n[ğŸš¨ æ•°å­—åŒ–èº«ï¼šè¿‘æœŸå®æ“æˆäº¤æµæ°´ (User Real-world Behavior Snapshot)]"]
                    # Last 5 trades descending
                    latest_trades = sorted(real_trades, key=lambda x: x['timestamp'], reverse=True)[:5]
                    for lt in latest_trades:
                        act = "ä¹°å…¥" if 'buy' in lt['type'] else ("å–å‡º" if 'sell' in lt['type'] else "ä¿®æ­£")
                        exec_lines.append(f"- {lt['timestamp']}: {act} {int(lt['amount'])}è‚¡ @ {lt['price']}")
                    final_research_context += "\n" + "\n".join(exec_lines)

                history_logs = load_production_log(symbol)
                if history_logs:
                    history_context_lines = ["\n[å†å²ç ”åˆ¤å‚è€ƒ (Previous AI Analysis & User Execution)]"]
                    
                    logs_asc = sorted(history_logs, key=lambda x: x['timestamp'])
                    # Limit to last 2 to prevent context overflow and distraction
                    recent_subset = logs_asc[-2:] 
                    
                    recent_subset = logs_asc[-2:] 
                    
                    import re
                    for idx, log in enumerate(recent_subset):
                        h_ts = log.get('timestamp', 'N/A')
                        h_res = log.get('result', '')
                        
                        # Extract ONLY the Decision Summary to save tokens and avoid hallucination from old reasoning
                        summary_match = re.search(r"ã€å†³ç­–æ‘˜è¦ã€‘(.*)", h_res, re.DOTALL)
                        if summary_match:
                             clean_res = "ã€å†³ç­–æ‘˜è¦ã€‘" + summary_match.group(1).strip()
                        else:
                             clean_res = h_res[:200] + "..." if len(h_res) > 200 else h_res

                        entry_header = f"\n--- History #{idx+1} ({h_ts}) ---"
                        history_context_lines.append(entry_header)
                        history_context_lines.append(f"{clean_res}")
                        
                        start_time = h_ts
                        full_idx = logs_asc.index(log)
                        if full_idx < len(logs_asc) - 1:
                            end_time = logs_asc[full_idx+1]['timestamp']
                        else:
                            end_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            
                        matched_tx = []
                        for t in real_trades:
                            # Parse timestamp string to datetime object for comparison if needed, 
                            # but assuming strings work if format is consistent ISO
                            if start_time <= t['timestamp'] < end_time:
                                 action = "ä¹°å…¥" if t['type'] == 'buy' else "å–å‡º"
                                 matched_tx.append(f"{action} {int(t['amount'])}è‚¡ @ {t['price']}")
                        
                        if matched_tx:
                             history_context_lines.append(f"ã€âš ï¸ ç”¨æˆ·å®é™…æ‰§è¡Œ (User Action)ã€‘: {'; '.join(matched_tx)}")
                        else:
                             history_context_lines.append(f"ã€ç”¨æˆ·å®é™…æ‰§è¡Œã€‘: (æ— æ“ä½œ / No Action)")

                    # Add User Action Summary (Holistic View)
                    pos_now = context_data.get('shares', 0)
                    cost_now = context_data.get('avg_cost', context_data.get('cost', 0))
                    base_locked = context_data.get('base_shares', 0)
                    price_now = float(context_data.get('price', 0))
                    
                    # [Context Fix] Calculate Position Ratios explicitly
                    total_cap = float(context_data.get('total_capital', 0))
                    alloc_cap = float(context_data.get('capital_allocation', 0))
                    avail_cash = float(context_data.get('available_cash', 0))
                    
                    mkt_val = pos_now * price_now
                    ratio_total = (mkt_val / total_cap * 100) if total_cap > 0 else 0
                    ratio_alloc = (mkt_val / alloc_cap * 100) if alloc_cap > 0 else 0
                    
                    history_context_lines.append(f"\nã€ç”¨æˆ·å½“å‰çŠ¶æ€çœ‹æ¿ (Position Health)ã€‘:")
                    history_context_lines.append(f"- æŒä»“çŠ¶æ€: æ€»æŒä»“ {pos_now} è‚¡ï¼Œæˆæœ¬ {cost_now:.4f}ï¼Œæœ€æ–°å¸‚å€¼ {int(mkt_val)}ã€‚")
                    history_context_lines.append(f"- ä»“ä½æ°´ä½: å æ€»èµ„é‡‘ **{ratio_total:.1f}%** (Total: {int(total_cap)})" + 
                                               (f"ï¼Œå å•è‚¡é™é¢ **{ratio_alloc:.1f}%** (Limit: {int(alloc_cap)})" if alloc_cap > 0 else "") + "ã€‚")
                    history_context_lines.append(f"- å‰©ä½™å¼¹è¯: å¯ç”¨ç°é‡‘ **{int(avail_cash)}**ã€‚")
                    
                    if base_locked > 0:
                        history_context_lines.append(f"ã€ğŸ”’ æ ¸å¿ƒç¦å¿Œã€‘: ç”¨æˆ·å·²é”å®šåº•ä»“ {base_locked} è‚¡ã€‚é™¤éæ¶‰åŠæ¸…ä»“ç¦»åœºï¼Œå¦åˆ™ä½ ä¸¥ç¦è§¦åŠ¨è¯¥åº•ä»“ã€‚")
                    
                    history_context_lines.append(f"ã€âš ï¸ æ•°å­—åŒ–èº«æŒ‡ä»¤ã€‘: æ·±åº¦æ€è€ƒä½ ä¹‹å‰çš„å»ºè®®æ˜¯å¦è¢«ç”¨æˆ·é‡‡çº³ï¼Ÿå¦‚æœæ˜¯è¢«æ‹’ç»äº†ï¼Œåˆ†æç”¨æˆ·å½“æ—¶é¿å¼€äº†ä»€ä¹ˆé£é™©ï¼Œæˆ–è€…åœ¨ç­‰å¾…ä»€ä¹ˆæœºä¼šï¼Ÿåœ¨æœ¬æ¬¡åŒ–èº«å†³ç­–ä¸­ï¼Œè¯·ç»§æ‰¿è¿™ä¸€è¡Œä¸ºæƒ¯æ€§å¹¶è¿›è¡Œä¼˜åŒ–ã€‚")
                    
                    final_research_context += "\n" + "\n".join(history_context_lines)
            except Exception as e:
                print(f"Error loading history for RAG: {e}")

        if intraday_summary:
            m_status = context_data.get('market_status')
            if m_status in ["PRE_OPEN", "CLOSED_NOON"]:
                # Pre-market or Noon: Intraday data is from YESTERDAY
                header = "[æ˜¨æ—¥åˆ†æ—¶ç›˜å£å›é¡¾ (Historical/Yesterday's Intraday)]"
            elif m_status == "CLOSED_POST":
                # Post-market: Intraday data is from TODAY
                header = "[ä»Šæ—¥åˆ†æ—¶ç‰¹å¾æ€»ç»“ (Today's Intraday Reflection)]"
            elif m_status == "OPEN_INTRADAY":
                header = "[ç›˜ä¸­å®æ—¶åˆ†æ—¶çŠ¶æ€]"
            else:
                header = "[åˆ†æ—¶ç›˜å£ç‰¹å¾æ±‡è¦]"
                
            if m_status == "OPEN_INTRADAY":
                final_research_context += f"\n\n{header}: {intraday_summary[:100]}..."
            else:
                final_research_context += f"\n\n{header}\n{intraday_summary}"

        suffix_data = {
            "daily_stats": technical_indicators.get('daily_stats', 'N/A'),
            "macd": technical_indicators.get('MACD', 'N/A'),
            "kdj": technical_indicators.get('KDJ', 'N/A'),
            "rsi": technical_indicators.get('RSI(14)', 'N/A'),
            "ma": technical_indicators.get('MA', 'N/A'),
            "bollinger": technical_indicators.get('Bollinger', 'N/A'),
            "tech_summary": technical_indicators.get('signal_summary', 'N/A'),
            "research_context": final_research_context,
            "capital_flow": capital_flow_str,
            "generated_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        
        # [Noon Review Enhanced] Inject Morning Stats (Defaults First)
        suffix_data.update({
            "morning_open": "N/A",
            "morning_high": "N/A",
            "morning_low": "N/A",
            "morning_close": "N/A",
            "morning_vol": "N/A"
        })
        
        if "morning_close" in context_data:
            suffix_data.update({
                "morning_open": context_data.get("morning_open", "N/A"),
                "morning_high": context_data.get("morning_high", "N/A"),
                "morning_low": context_data.get("morning_low", "N/A"),
                "morning_close": context_data.get("morning_close", "N/A"),
                "morning_vol": context_data.get("morning_vol", "N/A")
            })

        # Merge context_data to provide access to 'price', 'code', 'name' etc. in suffix
        if context_data:
            suffix_data.update(context_data)
        try:
            base_prompt += suffix_tpl.format(**suffix_data)
        except KeyError as e:
            base_prompt += f"\n[Suffix Error: Missing key {e}]"
            
    elif simple_suffix_tpl:
        base_prompt += simple_suffix_tpl

    # [PATCH] Label Correction for Post-Market
    # Old templates might hardcode "ä»Šæ—¥äº¤æ˜“è¾¹ç•Œ", but in CLOSED state we want "ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥è¾¹ç•Œ"
    if context_data.get('market_status') == 'CLOSED_POST':
        base_prompt = base_prompt.replace("ä»Šæ—¥äº¤æ˜“è¾¹ç•Œ", "ä¸‹ä¸ªäº¤æ˜“æ—¥é¢„è®¡è¾¹ç•Œ")
        base_prompt = base_prompt.replace("ä»Šæ—¥æ¶¨åœ", "ä¸‹æ—¥æ¶¨åœ").replace("ä»Šæ—¥è·Œåœ", "ä¸‹æ—¥è·Œåœ")

    # [OPTIMIZATION] Append Critical State Block at the VERY END for Recency Bias
    # This ensures the AI sees the most important numbers last, reducing calculation errors.
    if context_data:
        p = context_data.get('price', 0)
        cost = context_data.get('avg_cost', context_data.get('cost', 0))
        shares = context_data.get('shares', 0)
        cash = context_data.get('available_cash', 0)
        
        # Calculate max buy/sell for easy reference
        max_buy = int(cash / p) if p > 0 else 0
        max_buy = (max_buy // 100) * 100
        
        profit_pct = ((p - cost) / cost * 100) if cost > 0 else 0
        
        critical_block = f"""
\n################################################################
ã€ğŸ”´ æœ€ç»ˆå†³ç­–å…³é”®æ•°æ® (CRITICAL FACT SHEET) ğŸ”´ã€‘
> è¯·å¿½ç•¥ä¸Šæ–‡ä»»ä½•ä¸æ­¤å¤„å†²çªçš„æ•°æ®ï¼Œä»¥æœ¬æ ä¸ºå‡†è¿›è¡Œè®¡ç®—ã€‚
å½“å‰ä»·æ ¼: {p}
æŒä»“æ•°é‡: {shares} è‚¡
æŒä»“æˆæœ¬: {cost:.3f}
æµ®åŠ¨ç›ˆäº: {profit_pct:.2f}%
å¯ç”¨èµ„é‡‘: {cash:.2f}
æœ€å¤§å¯ä¹°: {max_buy} è‚¡
################################################################
"""
        base_prompt += critical_block

    # System Prompt (From Config)
    # Unified Strategy (LAG + GTO for All)
    sys_key = "proposer_system"
    default_sys = "You are a professional trader. Analyze the provided data and give actionable trading advice."
    
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    return system_prompt, base_prompt

def call_deepseek_api(api_key, system_prompt, user_prompt):
    """
    Executes the API call to DeepSeek.
    """
    if not api_key:
        return "Error: Missing API Key", ""

    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": "deepseek-reasoner",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.6
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=240)
        if response.status_code == 200:
            res_json = response.json()
            message = res_json['choices'][0]['message']
            content = message.get('content', '')
            reasoning = message.get('reasoning_content', '')
            return content, reasoning
        else:
            return f"API Error {response.status_code}: {response.text}", ""
    except Exception as e:
        return f"Request Failed: {e}", ""

def ask_deepseek_advisor(api_key, context_data, research_context="", technical_indicators=None, fund_flow_data=None, fund_flow_history=None, intraday_summary=None, prompt_templates=None, suffix_key="deepseek_research_suffix", symbol=None):
    """
    Wrapper for backward compatibility.
    """
    sys_p, user_p = build_advisor_prompt(
        context_data, research_context, technical_indicators, 
        fund_flow_data, fund_flow_history, intraday_summary, 
        prompt_templates, suffix_key, symbol
    )
    
    if "Error" in user_p and sys_p == "":
        return user_p, "", ""
        
    content, reasoning = call_deepseek_api(api_key, sys_p, user_p)
    return content, reasoning, user_p

def call_qwen_api(api_key, system_prompt, user_prompt, model="qwen-max"):
    """
    Executes the API call to Qwen (Tongyi Qianwen) via DashScope OpenAI-compatible endpoint.
    """
    if not api_key:
        return "Error: Missing Qwen API Key"

    # DashScope OpenAI Compatible Endpoint
    url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.5 # Conservative for auditing
    }
    
    try:
        # Increased timeout to 120s for complex reasoning
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        print(f"DEBUG: Qwen Status: {response.status_code}")
        if response.status_code != 200: print(f"DEBUG: Qwen Error: {response.text}")
        if response.status_code == 200:
            res_json = response.json()
            if 'choices' in res_json and len(res_json['choices']) > 0:
                content = res_json['choices'][0]['message'].get('content', '')
                return content
            return f"API Error: Empty response format {res_json}"
        else:
            return f"Qwen API Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"Qwen Request Failed: {str(e)}"

def build_red_team_prompt(context_data, prompt_templates=None, is_final_round=False):
    """
    Constructs System and User prompts for Red Team Audit.
    is_final_round: If True, this is the 2nd pass (Final Verdict).
    """
    if not prompt_templates: prompt_templates = {}
    
    # Defaults
    DEFAULT_RED_SYS = """
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„ã€Aè‚¡å¾·å·æ‰‘å…‹ LAG + GTO äº¤æ˜“ä¸“å®¶ã€‘ã€‚
ä½ ç°åœ¨æ‹…ä»»ã€ç­–ç•¥å®¡è®¡å¸ˆã€‘(Auditor)ï¼Œä½ çš„äº¤æ˜“å“²å­¦ä¸è“å†›ï¼ˆç­–ç•¥å¸ˆï¼‰å®Œå…¨ä¸€è‡´ï¼šLAG (æ¾å‡¶) + GTO (åšå¼ˆè®ºæœ€ä¼˜)ã€‚

ä½ çš„èŒè´£ä¸æ˜¯æ— è„‘åå¯¹é£é™©ï¼Œè€Œæ˜¯è¿›è¡Œã€ä¸€è‡´æ€§å®¡æŸ¥ã€‘ä¸ã€çº é”™ã€‘ï¼š
1. **å»å¹»è§‰ (De-Hallucination)**ï¼šè“å†›å¼•ç”¨çš„æ•°æ®ï¼ˆå¦‚èµ„é‡‘æµã€æ”¯æ’‘ä½ï¼‰æ˜¯å¦çœŸå®å­˜åœ¨ï¼Ÿæ˜¯å¦åŸºäºäº‹å®ï¼Ÿ
2. **æ ¸å®é€»è¾‘ (Logic Check)**ï¼šè“å†›çš„å†³ç­–æ˜¯å¦ç¬¦åˆ LAG + GTO ä½“ç³»ï¼Ÿ
   - è¿›æ”»æ€§æ£€æŸ¥ï¼šåœ¨å¤§æ¾å‡¶ (LAG) ä¿¡å·å‡ºç°æ—¶ï¼Œè“å†›æ˜¯å¦è¶³å¤Ÿæœæ–­ï¼Ÿæœ‰æ²¡æœ‰è¯¥ä¹°ä¸æ•¢ä¹°ï¼Ÿ
   - èµ”ç‡æ£€æŸ¥ï¼šGTO è§†è§’ä¸‹ï¼Œè¿™ç¬”äº¤æ˜“çš„ EV (æœŸæœ›å€¼) æ˜¯å¦ä¸ºæ­£ï¼Ÿæ­¢æŸèµ”ç‡æ˜¯å¦åˆç†ï¼Ÿ

ç›®æ ‡ï¼šç¡®ä¿è“å†›çš„ç­–ç•¥æ˜¯è¯¥ä½“ç³»ä¸‹çš„**æœ€ä¼˜è§£**ã€‚å¦‚æœä¸è®¤å¯ï¼Œè¯·æŒ‡å‡ºè¿èƒŒäº†å“ªæ¡äº¤æ˜“åŸåˆ™ã€‚
ç‚¹è¯„é£æ ¼ï¼šåƒä¸€ä½ä¸¥æ ¼çš„å¾·æ‰‘æ•™ç»ƒï¼Œä¸€é’ˆè§è¡€ï¼Œé€šè¿‡æ•°æ®å’Œé€»è¾‘è¯´è¯ã€‚
"""
    if is_final_round:
        DEFAULT_RED_SYS += "\nã€æ³¨æ„ã€‘è¿™æ˜¯**æœ€ç»ˆè½®**å®¡æŸ¥ã€‚å¦‚æœè“å†›å·²ç»æ ¹æ®ä½ çš„å‰æ¬¡æ„è§ä¿®æ­£äº†ç­–ç•¥ï¼Œä¸”é£é™©å·²é€šè¿‡ï¼Œè¯·ç›´æ¥æ‰¹å‡†ã€‚"

    DEFAULT_RED_USER = """
ã€å®¡è®¡ä¸Šä¸‹æ–‡ã€‘
äº¤æ˜“æ—¥æœŸ: {date}
æ ‡çš„: {code} ({name})
å½“å‰ä»·æ ¼: {price}

ã€è“å†›æŒæ¡çš„æƒ…æŠ¥ (å¯ä¿¡äº‹å®)ã€‘
{daily_stats}

ã€è“å†›ç­–ç•¥æ–¹æ¡ˆ (å¾…å®¡æŸ¥)ã€‘
{deepseek_plan}

ã€å®¡è®¡ä»»åŠ¡ã€‘
è¯·ä»¥ã€LAG + GTO ä¸“å®¶ã€‘çš„èº«ä»½å¯¹ä¸Šè¿°ç­–ç•¥è¿›è¡ŒåŒè¡Œè¯„å®¡ (Peer Review)ã€‚
ä¸è¦åšä¿å®ˆçš„é£æ§å®˜ï¼Œè¦åš**è¿½æ±‚æ­£æœŸæœ›å€¼çš„èµŒæ‰‹æ•™ç»ƒ**ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
1. **çœŸå®æ€§æ ¸æŸ¥**: 
   - è“å†›æ˜¯å¦æé€ äº†æ•°æ®ï¼Ÿ(é€šè¿‡/æœªé€šè¿‡)
2. **LAG/GTO ä½“ç³»è¯„ä¼°**: 
   - è¿›æ”»æ¬²æœ›æ˜¯å¦åŒ¹é…å½“å‰ç‰Œé¢ï¼Ÿ(æ˜¯/å¦, ç†ç”±)
   - èµ”ç‡è®¡ç®—æ˜¯å¦åˆç†ï¼Ÿ
3. **ä¸“å®¶æœ€ç»ˆè£å†³**: (æ‰¹å‡†æ‰§è¡Œ / å»ºè®®ä¿®æ­£ / é©³å›é‡åš)
   - *å¦‚æœæ˜¯å»ºè®®ä¿®æ­£ï¼Œè¯·ç»™å‡ºå…·ä½“çš„ GTO è°ƒæ•´å»ºè®®ã€‚*
"""
    if is_final_round:
        # Try to get dedicated Final Audit template
        if "reviewer_final_audit" in prompt_templates:
            user_tpl = prompt_templates["reviewer_final_audit"]
            # We don't append the default suffix if we have a custom final template
            # assuming the custom template handles the "Final Round" context.
        else:
            # Fallback to shared audit template + Suffix
            user_tpl = prompt_templates.get("reviewer_audit", DEFAULT_RED_USER)
            user_tpl += "\nã€æœ€ç»ˆè£å†³è¦æ±‚ã€‘è¿™æ˜¯è“å†›ä¿®æ­£åçš„ v2.0 ç‰ˆæœ¬ã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„éšæ‚£æ˜¯å¦æ¶ˆé™¤ã€‚å¦‚æœ‰æ ¸å¿ƒé—®é¢˜æœªè§£å†³ï¼Œä»å¯é©³å›ï¼›å¦åˆ™è¯·æ‰¹å‡†æ‰§è¡Œã€‚"
    else:
        # [Noon Audit Logic]
        if context_data.get('market_status') == "CLOSED_NOON" and "reviewer_noon_audit" in prompt_templates:
            user_tpl = prompt_templates["reviewer_noon_audit"]
        else:
            user_tpl = prompt_templates.get("reviewer_audit", DEFAULT_RED_USER)
        
    sys_tpl = prompt_templates.get("reviewer_system", DEFAULT_RED_SYS)
    
    try:
        user_prompt = user_tpl.format(**context_data)
        
        # [PATCH] Inject History if available (for Final Verdict)
        if context_data.get('history_summary'):
             # Prepend context so the auditor reads history first, then the current plan
             user_prompt = f"{context_data['history_summary']}\n\n{user_prompt}"

        if is_final_round and "reviewer_final_audit" not in prompt_templates:
            user_prompt += "\n\n(This is the Final Round Audit for v2.0)"
            
        system_prompt = sys_tpl
        return system_prompt, user_prompt
    except Exception as e:
        return "", f"Prompt Format Error: {e}"

def call_kimi_api(api_key, system_prompt, user_prompt, model="kimi-k2.5", base_url="https://api.moonshot.cn/v1"):
    """
    Executes the API call to Kimi (Moonshot AI).
    Compatible with OpenAI SDK pattern.
    """
    if not api_key:
        return "Error: Missing Kimi API Key"

    clean_key = api_key.strip()
    # Correctly join the base_url with the path
    import os
    if base_url.endswith('/'):
        base_url = base_url[:-1]
    url = f"{base_url}/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {clean_key}"
    }
    
    # Debug: Print Sanitized Info to Terminal
    print(f"DEBUG KIMI: URL={url} MODEL={model} KEY_PFX={clean_key[:8]}...")
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 1.0 # kimi-k2.5 requires exactly 1.0
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        if response.status_code == 200:
            res_json = response.json()
            if 'choices' in res_json and len(res_json['choices']) > 0:
                content = res_json['choices'][0]['message'].get('content', '')
                return content
            return f"Kimi API Error: Empty response format {res_json}"
        else:
            k_len = len(clean_key)
            k_pfx = clean_key[:5] if k_len > 5 else clean_key
            return f"Kimi API Error {response.status_code}: {response.text} (Key: {k_pfx}..., Len: {k_len})"
    except Exception as e:
        return f"Kimi Request Failed: {str(e)}"

def call_ai_model(model_name, api_key, system_prompt, user_prompt, specific_model=None, base_url=None):
    """
    Unified dispatcher for AI models.
    model_name: "deepseek", "qwen", or "kimi"
    specific_model: (Optional) specific model ID.
    """
    if model_name == "deepseek":
        content, reasoning = call_deepseek_api(api_key, system_prompt, user_prompt)
        return content, reasoning
    elif model_name == "qwen":
        target_model = specific_model if specific_model else "qwen-max"
        content = call_qwen_api(api_key, system_prompt, user_prompt, model=target_model)
        return content, ""
    elif model_name == "kimi":
        target_model = specific_model if specific_model else "kimi-k2.5"
        # If base_url is not provided, use the one from call_kimi_api default (or we could fetch from config here)
        if base_url:
            content = call_kimi_api(api_key, system_prompt, user_prompt, model=target_model, base_url=base_url)
        else:
            content = call_kimi_api(api_key, system_prompt, user_prompt, model=target_model)
        return content, ""
    else:
        return f"Error: Unknown Model {model_name}", ""

def ask_qwen_advisor(api_key, context_data, prompt_templates=None):
    """
    Calls Qwen (DashScope) for second opinion (Red Team).
    Legacy wrapper using the new builder.
    """
    sys_p, user_p = build_red_team_prompt(context_data, prompt_templates)
    if "Error" in user_p and sys_p == "":
        return user_p
        
    return call_qwen_api(api_key, sys_p, user_p)

def build_refinement_prompt(original_context, original_plan, audit_report, prompt_templates=None):
    """
    Constructs the Full Prompt for Strategy Refinement.
    """
    if not prompt_templates: prompt_templates = {}
    
    # 1. Reuse Original System Prompt logic (Role persistence)
    # Ideally should match the Blue Team's original system prompt
    sys_key = "proposer_system"
    default_sys = "You are a professional trader."
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    # 2. Build Refinement Instruction (User Prompt)
    # Default instruction incorporating "Blue Team Autonomy"
    default_refine_instr = "Please refine the strategy based on the audit feedback."
    refine_tpl = prompt_templates.get("refinement_instruction", default_refine_instr)
    
    try:
        user_prompt = refine_tpl.format(audit_report=audit_report)
        
        # MEGA PROMPT CONSTRUCTION:
        # [Context] -> [Plan] -> [Audit] -> [Refine Instruction]
        full_user_prompt = f"""
{original_context}

ã€å‰æ¬¡ç­–ç•¥ (Draft v1.0)ã€‘
{original_plan}

{user_prompt}
"""
        return system_prompt, full_user_prompt
    except Exception as e:
        return "", f"Refinement Prompt Error: {e}"

def build_final_decision_prompt(aggregated_history: list, prompt_templates=None, context_data=None):
    """
    Constructs the prompt for Step 5: Final Decision using aggregated history.
    aggregated_history: List of strings or dictionaries containing previous steps info.
    """
    if not prompt_templates: prompt_templates = {}
    
    # 1. Extract symbol/name to anchor
    target_info = "å½“å‰æ“ä½œæ ‡çš„"
    if context_data:
        code = context_data.get('code', 'N/A')
        name = context_data.get('name', 'N/A')
        target_info = f"ã€{code} / {name}ã€‘"

    # 2. Aggregating History with Structural Semantic Labels [v4.3 Enhanced]
    labels = [
        "ã€1. è“å†›åˆå§‹è‰æ¡ˆ (Draft v1.0)ã€‘",
        "ã€2. çº¢å†›åˆå®¡å®¡è®¡ (Audit Round 1)ã€‘",
        "ã€3. è“å†›åæ€ä¼˜åŒ– (Refined Strategy v2.0)ã€‘",
        "ã€4. çº¢å†›ç»ˆæè£å†³ (Final Verdict)ã€‘"
    ]
    
    if isinstance(aggregated_history, str):
        history_text = f"ã€åšå¼ˆè®°å½•ã€‘:\n{aggregated_history}"
    else:
        history_items = []
        for i, step in enumerate(aggregated_history):
            label = labels[i] if i < len(labels) else f"ã€å›åˆ #{i+1}ã€‘"
            history_items.append(f"{label}\n{step}")
        history_text = "\n\n".join(history_items)

    # 2b. [CRITICAL] Re-inject Initial Context (è¡Œæƒ…èƒŒæ™¯)
    # This prevents the "Context Vacuum" during the final signature
    core_context = ""
    if context_data:
        p = context_data.get('price', '--')
        pc = context_data.get('pre_close', '--')
        cp = context_data.get('change_pct', 0.0)
        core_context = f"""
### [æ ¸å¿ƒè¡Œæƒ…å¿«ç…§ (Base Context Re-injection)]
æ ‡çš„: {target_info}
æœ€æ–°ä»·: {p} | æ˜¨æ”¶: {pc} | æ¶¨è·Œå¹…: {cp:.2f}%
å½“å‰æŒä»“: {context_data.get('shares', 0)} è‚¡ | æˆæœ¬: {context_data.get('cost', 0)}
"""

    # 3. System Prompt (Reuse Blue Team)
    sys_key = "proposer_system"
    default_sys = f"You are a professional trader analyzing {target_info}."
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    # 4. User Prompt (Decision Instruction)
    # Using triple-quoted string to ensure formatting
    default_instr = f"Please review the strategy history and provide a final trading decision for {target_info}."
    user_tpl = prompt_templates.get("proposer_final_decision", default_instr)
    
    try:
        # Note: If user_tpl contains other keys, this might need refinement
        user_prompt = user_tpl.format(
            core_context=core_context,
            target_info=target_info,
            history_text=history_text
        )
        return system_prompt, user_prompt
    except Exception as e:
        return system_prompt, default_instr # Fallback

def ask_ai_refinement(model_name, api_key, original_context, original_plan, audit_report, prompt_templates=None):
    """
    Asks the Blue Team to refine the strategy based on Red Team audit.
    Legacy wrapper using the new builder.
    """
    if not api_key: return "Error: Missing API Key"
    
    sys_p, user_p = build_refinement_prompt(original_context, original_plan, audit_report, prompt_templates)
    if "Error" in user_p and sys_p == "":
        return user_p, ""
        
    return call_ai_model(model_name, api_key, sys_p, user_p)
