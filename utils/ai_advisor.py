import requests
import json
import pandas as pd
from datetime import datetime

from google import genai
from utils.storage import load_production_log
from utils.data_fetcher import calculate_price_limits
from utils.database import db_get_history

def build_advisor_prompt(context_data, research_context="", technical_indicators=None, fund_flow_data=None, fund_flow_history=None, intraday_summary=None, prompt_templates=None, suffix_key="proposer_premarket_suffix", symbol=None):
    """
    Constructs the System Prompt and User Prompt for the AI Advisor.
    Returns: (system_prompt, user_prompt)
    """
    if not prompt_templates: prompt_templates = {}
    
    base_tpl = prompt_templates.get("proposer_base", "")
    suffix_tpl = prompt_templates.get(suffix_key, "")
    simple_suffix_tpl = prompt_templates.get("proposer_simple_suffix", "")
    
    if not base_tpl:
        return "", "Error: Prompt templates missing."

    # [Logic] Phase Determination based on Time
    now = datetime.now()
    hour, minute = now.hour, now.minute
    
    # Define Tunnels
    is_pre_market = (hour < 9) or (hour == 9 and minute < 30)
    is_noon_break = (hour == 11 and minute >= 30) or (hour == 12) or (hour == 13 and minute < 0)
    is_post_market = (hour >= 15) or (hour == 14 and minute >= 55)
    
    if is_post_market:
        shift = 1
        if now.weekday() == 4: shift = 3
        elif now.weekday() == 5: shift = 2
        target_date = now + pd.Timedelta(days=shift)
        context_data['date'] = f"{target_date.strftime('%Y-%m-%d')} (Next Trading Day)"
        context_data['market_status'] = "CLOSED_POST"
    elif is_noon_break:
        context_data['market_status'] = "CLOSED_NOON"
    elif is_pre_market:
        context_data['market_status'] = "PRE_OPEN"
    else:
        # Intraday - Focused on monitoring, not re-planning unless it's a critical node
        context_data['market_status'] = "OPEN_INTRADAY"
        # Optional: Add a note that this is NOT a formal review node
        research_context += "\nã€âš ï¸ æç¤ºã€‘: å½“å‰å¤„äºç›˜ä¸­äº¤æ˜“æ—¶æ®µï¼Œå»ºè®®ä»¥è§‚å¯Ÿä¸ºä¸»ï¼Œå¾…åˆé—´æˆ–ç›˜åå†è¿›è¡Œæ­£å¼ç­–ç•¥ä¿®å®šã€‚"

    # 2. Format Base
    # Calculate Price Limits
    if 'code' in context_data:
         # [Business Logic] Base Price Selection for Limit Calculation
         m_status = context_data.get('market_status')
         
         if m_status == "CLOSED_POST":
             # Post-market: Forecasting for NEXT Day, use Today's Close as base
             limit_base = float(context_data.get('price', 0))
         else:
             # Pre-market or Noon-market: Working with TODAY's limits, use Yesterday's Close as base
             # Even if 'limit_base_price' is passed from UI, we override it for correctness in NOON mode
             limit_base = float(context_data.get('pre_close', 0))
             
         if limit_base == 0: 
             limit_base = float(context_data.get('price', 0))
         
         l_up, l_down = calculate_price_limits(
             context_data.get('code', ''),
             context_data.get('name', ''),
             limit_base
         )
         context_data['limit_up'] = l_up
         context_data['limit_down'] = l_down
    else:
         context_data['limit_up'] = "N/A"
         context_data['limit_down'] = "N/A"

    try:
        base_prompt = base_tpl.format(**context_data)
    except KeyError as e:
        base_prompt = f"Prompt Error: Missing key {e}"

    # 3. Append Suffix
    if technical_indicators and suffix_tpl:
        # Prepare data for suffix
        
        # Format Fund Flow
        capital_flow_str = "N/A"
        if fund_flow_data and not fund_flow_data.get("error"):
            flow_lines = [f"{k}: {v}" for k, v in fund_flow_data.items()]
            fund_lines = [" | ".join(flow_lines)]
        elif fund_flow_data and fund_flow_data.get("error"):
            fund_lines = [f"å½“æ—¥æ•°æ®è·å–å¤±è´¥: {fund_flow_data.get('error')}"]
        else:
            fund_lines = []

        # Format History Fund Flow
        if fund_flow_history is not None and not fund_flow_history.empty:
            try:
                recent = fund_flow_history.tail(20)
                table_lines = ["\n**è¿‘20äº¤æ˜“æ—¥èµ„é‡‘æµå‘è¶‹åŠ¿:**", "| æ—¥æœŸ | æ”¶ç›˜ | æ¶¨è·Œ% | ä¸»åŠ›å‡€æµå…¥(ä¸‡) | è¶…å¤§å•(ä¸‡) | å¤§å•(ä¸‡) |", "|---|---|---|---|---|---|"]
                
                total_main_flow = 0.0
                positive_flow_days = 0
                total_days = len(recent)

                for _, row in recent.iterrows():
                    d = row['æ—¥æœŸ'].strftime('%m-%d') if hasattr(row['æ—¥æœŸ'], 'strftime') else str(row['æ—¥æœŸ'])[:10]
                    c = row.get('æ”¶ç›˜ä»·', 0)
                    p = row.get('æ¶¨è·Œå¹…', 0)
                    if pd.isna(p): p = 0
                    
                    raw_main = row.get('ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0)
                    if not pd.isna(raw_main):
                        total_main_flow += float(raw_main)
                        if float(raw_main) > 0:
                            positive_flow_days += 1

                    def to_wan(v):
                        try:
                            if pd.isna(v): return "0"
                            return f"{float(v)/10000:.0f}"
                        except:
                            return str(v)
                            
                    m_flow = to_wan(row.get('ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 0))
                    s_flow = to_wan(row.get('è¶…å¤§å•å‡€æµå…¥-å‡€é¢', 0))
                    b_flow = to_wan(row.get('å¤§å•å‡€æµå…¥-å‡€é¢', 0))
                    
                    table_lines.append(f"| {d} | {c} | {p:.2f} | {m_flow} | {s_flow} | {b_flow} |")
                
                fund_lines.append("\n".join(table_lines))
                
                flow_trend = "æµå…¥" if total_main_flow > 0 else "æµå‡º"
                summary_line = (
                    f"\nã€èµ„é‡‘ç»Ÿè®¡ã€‘è¿‘{total_days}æ—¥ä¸»åŠ›ç´¯è®¡å‡€{flow_trend} {abs(total_main_flow)/10000:.1f}ä¸‡ã€‚ "
                    f"å…¶ä¸­ {positive_flow_days} å¤©ä¸ºå‡€æµå…¥ï¼ˆå æ¯” {positive_flow_days/total_days:.0%}ï¼‰ã€‚"
                )
                fund_lines.append(summary_line)

            except Exception as e:
                fund_lines.append(f"\n(å†å²æ•°æ®æ ¼å¼åŒ–é”™è¯¯: {e})")
        
        capital_flow_str = "\n".join(fund_lines) if fund_lines else "N/A"
        
        # Format RAG Context (History + Execution)
        final_research_context = research_context if research_context else "æ— æƒ…æŠ¥"
        
        if symbol:
            try:
                history_logs = load_production_log(symbol)
                if history_logs:
                    # 1. Get Trades
                    # 1. Get Trades
                    all_trades = db_get_history(symbol)
                    
                    # STRICT FILTER: Only include explicit Buy/Sell actions.
                    # Exclude 'override', 'correction', 'allocation' to prevent DeepSeek double-counting corrections as new trades.
                    valid_types = ['buy', 'sell']
                    real_trades = []
                    for t in all_trades:
                        t_type = str(t.get('type', '')).strip().lower()
                        if t_type in valid_types and t.get('amount', 0) > 0:
                            # Standardize type for downstream logic
                            t['type'] = t_type 
                            real_trades.append(t)
                    
                    history_context_lines = ["\n[å†å²ç ”åˆ¤å‚è€ƒ (Previous AI Analysis & User Execution)]"]
                    
                    logs_asc = sorted(history_logs, key=lambda x: x['timestamp'])
                    # Limit to last 2 to prevent context overflow and distraction
                    recent_subset = logs_asc[-2:] 
                    
                    recent_subset = logs_asc[-2:] 
                    
                    import re
                    for idx, log in enumerate(recent_subset):
                        h_ts = log.get('timestamp', 'N/A')
                        h_res = log.get('result', '')
                        
                        # Extract ONLY the Decision Summary to save tokens and avoid hallucination from old reasoning
                        summary_match = re.search(r"ã€å†³ç­–æ‘˜è¦ã€‘(.*)", h_res, re.DOTALL)
                        if summary_match:
                             clean_res = "ã€å†³ç­–æ‘˜è¦ã€‘" + summary_match.group(1).strip()
                        else:
                             clean_res = h_res[:200] + "..." if len(h_res) > 200 else h_res

                        entry_header = f"\n--- History #{idx+1} ({h_ts}) ---"
                        history_context_lines.append(entry_header)
                        history_context_lines.append(f"{clean_res}")
                        
                        start_time = h_ts
                        full_idx = logs_asc.index(log)
                        if full_idx < len(logs_asc) - 1:
                            end_time = logs_asc[full_idx+1]['timestamp']
                        else:
                            end_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            
                        matched_tx = []
                        for t in real_trades:
                            # Parse timestamp string to datetime object for comparison if needed, 
                            # but assuming strings work if format is consistent ISO
                            if start_time <= t['timestamp'] < end_time:
                                 action = "ä¹°å…¥" if t['type'] == 'buy' else "å–å‡º"
                                 matched_tx.append(f"{action} {int(t['amount'])}è‚¡ @ {t['price']}")
                        
                        if matched_tx:
                             history_context_lines.append(f"ã€âš ï¸ ç”¨æˆ·å®é™…æ‰§è¡Œ (User Action)ã€‘: {'; '.join(matched_tx)}")
                        else:
                             history_context_lines.append(f"ã€ç”¨æˆ·å®é™…æ‰§è¡Œã€‘: (æ— æ“ä½œ / No Action)")

                        # SKIP Reasoning to prevent context pollution
                    
                    # Add Disclaimer
                    history_context_lines.append(f"\n[Important]: ä»¥ä¸Šæ˜¯å†å²æ•°æ®ã€‚å½“å‰æœ€æ–°ä»·æ ¼è¯·ä»¥é¡¶éƒ¨ã€å½“å‰æ‰‹ç‰Œæ•°æ®ã€‘ä¸ºå‡† ({context_data.get('price', 'Unknown')})ã€‚")
                    
                    final_research_context += "\n" + "\n".join(history_context_lines)
            except Exception as e:
                print(f"Error loading history for RAG: {e}")

        if intraday_summary:
            m_status = context_data.get('market_status')
            if m_status in ["PRE_OPEN", "CLOSED_NOON"]:
                # Pre-market or Noon: Intraday data is from YESTERDAY
                header = "[æ˜¨æ—¥åˆ†æ—¶ç›˜å£å›é¡¾ (Historical/Yesterday's Intraday)]"
            elif m_status == "CLOSED_POST":
                # Post-market: Intraday data is from TODAY
                header = "[ä»Šæ—¥åˆ†æ—¶ç‰¹å¾æ€»ç»“ (Today's Intraday Reflection)]"
            elif m_status == "OPEN_INTRADAY":
                header = "[ç›˜ä¸­å®æ—¶åˆ†æ—¶çŠ¶æ€]"
            else:
                header = "[åˆ†æ—¶ç›˜å£ç‰¹å¾æ±‡è¦]"
                
            if m_status == "OPEN_INTRADAY":
                final_research_context += f"\n\n{header}: {intraday_summary[:100]}..."
            else:
                final_research_context += f"\n\n{header}\n{intraday_summary}"

        suffix_data = {
            "daily_stats": technical_indicators.get('daily_stats', 'N/A'),
            "macd": technical_indicators.get('MACD', 'N/A'),
            "kdj": technical_indicators.get('KDJ', 'N/A'),
            "rsi": technical_indicators.get('RSI(14)', 'N/A'),
            "ma": technical_indicators.get('MA', 'N/A'),
            "bollinger": technical_indicators.get('Bollinger', 'N/A'),
            "tech_summary": technical_indicators.get('signal_summary', 'N/A'),
            "research_context": final_research_context,
            "capital_flow": capital_flow_str,
            "generated_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        # Merge context_data to provide access to 'price', 'code', 'name' etc. in suffix
        if context_data:
            suffix_data.update(context_data)
        try:
            base_prompt += suffix_tpl.format(**suffix_data)
        except KeyError as e:
            base_prompt += f"\n[Suffix Error: Missing key {e}]"
            
    elif simple_suffix_tpl:
        base_prompt += simple_suffix_tpl

    # [PATCH] Label Correction for Post-Market
    # Old templates might hardcode "ä»Šæ—¥äº¤æ˜“è¾¹ç•Œ", but in CLOSED state we want "ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥è¾¹ç•Œ"
    if context_data.get('market_status') == 'CLOSED_POST':
        base_prompt = base_prompt.replace("ä»Šæ—¥äº¤æ˜“è¾¹ç•Œ", "ä¸‹ä¸ªäº¤æ˜“æ—¥é¢„è®¡è¾¹ç•Œ")
        base_prompt = base_prompt.replace("ä»Šæ—¥æ¶¨åœ", "ä¸‹æ—¥æ¶¨åœ").replace("ä»Šæ—¥è·Œåœ", "ä¸‹æ—¥è·Œåœ")

    # [OPTIMIZATION] Append Critical State Block at the VERY END for Recency Bias
    # This ensures the AI sees the most important numbers last, reducing calculation errors.
    if context_data:
        p = context_data.get('price', 0)
        cost = context_data.get('avg_cost', context_data.get('cost', 0))
        shares = context_data.get('shares', 0)
        cash = context_data.get('available_cash', 0)
        
        # Calculate max buy/sell for easy reference
        max_buy = int(cash / p) if p > 0 else 0
        max_buy = (max_buy // 100) * 100
        
        profit_pct = ((p - cost) / cost * 100) if cost > 0 else 0
        
        critical_block = f"""
\n################################################################
ã€ğŸ”´ æœ€ç»ˆå†³ç­–å…³é”®æ•°æ® (CRITICAL FACT SHEET) ğŸ”´ã€‘
> è¯·å¿½ç•¥ä¸Šæ–‡ä»»ä½•ä¸æ­¤å¤„å†²çªçš„æ•°æ®ï¼Œä»¥æœ¬æ ä¸ºå‡†è¿›è¡Œè®¡ç®—ã€‚
å½“å‰ä»·æ ¼: {p}
æŒä»“æ•°é‡: {shares} è‚¡
æŒä»“æˆæœ¬: {cost:.3f}
æµ®åŠ¨ç›ˆäº: {profit_pct:.2f}%
å¯ç”¨èµ„é‡‘: {cash:.2f}
æœ€å¤§å¯ä¹°: {max_buy} è‚¡
################################################################
"""
        base_prompt += critical_block

    # System Prompt
    # System Prompt (From Config)
    # System Prompt (From Config)
    # Unified Strategy (LAG + GTO for All)
    sys_key = "proposer_system"
    default_sys = (
        "ä½ é‚£ä½ä¸“ä¸šçš„è‚¡ç¥¨äº¤æ˜“å‘˜ï¼Œå¥‰è¡Œ 'LAG + GTO' äº¤æ˜“å“²å­¦ã€‚\n"
        "ã€æ ¸å¿ƒå¿ƒæ³•ã€‘ï¼šåˆ«äººææƒ§æˆ‘è´ªå©ªï¼Œåˆ«äººè´ªå©ªæˆ‘ææƒ§ã€‚\n"
        "è¯·åŸºäºæä¾›çš„æ•°æ®ï¼ˆåŒ…å«èµ„é‡‘æµå‘ã€åˆ†æ—¶ç‰¹å¾ã€æŠ€æœ¯æŒ‡æ ‡ã€å¸‚åœºæƒ…æŠ¥ä»¥åŠå†å²ç ”åˆ¤è®°å½•ï¼‰ç»™å‡ºæ˜ç¡®çš„æ“ä½œå»ºè®®ã€‚"
    )
    
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    return system_prompt, base_prompt

def call_deepseek_api(api_key, system_prompt, user_prompt):
    """
    Executes the API call to DeepSeek.
    """
    if not api_key:
        return "Error: Missing API Key", ""

    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": "deepseek-reasoner",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.6
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=90)
        if response.status_code == 200:
            res_json = response.json()
            message = res_json['choices'][0]['message']
            content = message.get('content', '')
            reasoning = message.get('reasoning_content', '')
            return content, reasoning
        else:
            return f"API Error {response.status_code}: {response.text}", ""
    except Exception as e:
        return f"Request Failed: {e}", ""

def ask_deepseek_advisor(api_key, context_data, research_context="", technical_indicators=None, fund_flow_data=None, fund_flow_history=None, intraday_summary=None, prompt_templates=None, suffix_key="deepseek_research_suffix", symbol=None):
    """
    Wrapper for backward compatibility.
    """
    sys_p, user_p = build_advisor_prompt(
        context_data, research_context, technical_indicators, 
        fund_flow_data, fund_flow_history, intraday_summary, 
        prompt_templates, suffix_key, symbol
    )
    
    if "Error" in user_p and sys_p == "":
        return user_p, "", ""
        
    content, reasoning = call_deepseek_api(api_key, sys_p, user_p)
    return content, reasoning, user_p

def call_qwen_api(api_key, system_prompt, user_prompt, model="qwen-max"):
    """
    Executes the API call to Qwen (Tongyi Qianwen) via DashScope OpenAI-compatible endpoint.
    """
    if not api_key:
        return "Error: Missing Qwen API Key"

    # DashScope OpenAI Compatible Endpoint
    url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.5 # Conservative for auditing
    }
    
    try:
        # Increased timeout to 120s for complex reasoning
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        print(f"DEBUG: Qwen Status: {response.status_code}")
        if response.status_code != 200: print(f"DEBUG: Qwen Error: {response.text}")
        if response.status_code == 200:
            res_json = response.json()
            if 'choices' in res_json and len(res_json['choices']) > 0:
                content = res_json['choices'][0]['message'].get('content', '')
                return content
            return f"API Error: Empty response format {res_json}"
        else:
            return f"Qwen API Error {response.status_code}: {response.text}"
    except Exception as e:
        return f"Qwen Request Failed: {str(e)}"

def build_red_team_prompt(context_data, prompt_templates=None, is_final_round=False):
    """
    Constructs System and User prompts for Red Team Audit.
    is_final_round: If True, this is the 2nd pass (Final Verdict).
    """
    if not prompt_templates: prompt_templates = {}
    
    # Defaults
    DEFAULT_RED_SYS = """
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„ã€Aè‚¡å¾·å·æ‰‘å…‹ LAG + GTO äº¤æ˜“ä¸“å®¶ã€‘ã€‚
ä½ ç°åœ¨æ‹…ä»»ã€ç­–ç•¥å®¡è®¡å¸ˆã€‘(Auditor)ï¼Œä½ çš„äº¤æ˜“å“²å­¦ä¸è“å†›ï¼ˆç­–ç•¥å¸ˆï¼‰å®Œå…¨ä¸€è‡´ï¼šLAG (æ¾å‡¶) + GTO (åšå¼ˆè®ºæœ€ä¼˜)ã€‚

ä½ çš„èŒè´£ä¸æ˜¯æ— è„‘åå¯¹é£é™©ï¼Œè€Œæ˜¯è¿›è¡Œã€ä¸€è‡´æ€§å®¡æŸ¥ã€‘ä¸ã€çº é”™ã€‘ï¼š
1. **å»å¹»è§‰ (De-Hallucination)**ï¼šè“å†›å¼•ç”¨çš„æ•°æ®ï¼ˆå¦‚èµ„é‡‘æµã€æ”¯æ’‘ä½ï¼‰æ˜¯å¦çœŸå®å­˜åœ¨ï¼Ÿæ˜¯å¦åŸºäºäº‹å®ï¼Ÿ
2. **æ ¸å®é€»è¾‘ (Logic Check)**ï¼šè“å†›çš„å†³ç­–æ˜¯å¦ç¬¦åˆ LAG + GTO ä½“ç³»ï¼Ÿ
   - è¿›æ”»æ€§æ£€æŸ¥ï¼šåœ¨å¤§æ¾å‡¶ (LAG) ä¿¡å·å‡ºç°æ—¶ï¼Œè“å†›æ˜¯å¦è¶³å¤Ÿæœæ–­ï¼Ÿæœ‰æ²¡æœ‰è¯¥ä¹°ä¸æ•¢ä¹°ï¼Ÿ
   - èµ”ç‡æ£€æŸ¥ï¼šGTO è§†è§’ä¸‹ï¼Œè¿™ç¬”äº¤æ˜“çš„ EV (æœŸæœ›å€¼) æ˜¯å¦ä¸ºæ­£ï¼Ÿæ­¢æŸèµ”ç‡æ˜¯å¦åˆç†ï¼Ÿ

ç›®æ ‡ï¼šç¡®ä¿è“å†›çš„ç­–ç•¥æ˜¯è¯¥ä½“ç³»ä¸‹çš„**æœ€ä¼˜è§£**ã€‚å¦‚æœä¸è®¤å¯ï¼Œè¯·æŒ‡å‡ºè¿èƒŒäº†å“ªæ¡äº¤æ˜“åŸåˆ™ã€‚
ç‚¹è¯„é£æ ¼ï¼šåƒä¸€ä½ä¸¥æ ¼çš„å¾·æ‰‘æ•™ç»ƒï¼Œä¸€é’ˆè§è¡€ï¼Œé€šè¿‡æ•°æ®å’Œé€»è¾‘è¯´è¯ã€‚
"""
    if is_final_round:
        DEFAULT_RED_SYS += "\nã€æ³¨æ„ã€‘è¿™æ˜¯**æœ€ç»ˆè½®**å®¡æŸ¥ã€‚å¦‚æœè“å†›å·²ç»æ ¹æ®ä½ çš„å‰æ¬¡æ„è§ä¿®æ­£äº†ç­–ç•¥ï¼Œä¸”é£é™©å·²é€šè¿‡ï¼Œè¯·ç›´æ¥æ‰¹å‡†ã€‚"

    DEFAULT_RED_USER = """
ã€å®¡è®¡ä¸Šä¸‹æ–‡ã€‘
äº¤æ˜“æ—¥æœŸ: {date}
æ ‡çš„: {code} ({name})
å½“å‰ä»·æ ¼: {price}

ã€è“å†›æŒæ¡çš„æƒ…æŠ¥ (å¯ä¿¡äº‹å®)ã€‘
{daily_stats}

ã€è“å†›ç­–ç•¥æ–¹æ¡ˆ (å¾…å®¡æŸ¥)ã€‘
{deepseek_plan}

ã€å®¡è®¡ä»»åŠ¡ã€‘
è¯·ä»¥ã€LAG + GTO ä¸“å®¶ã€‘çš„èº«ä»½å¯¹ä¸Šè¿°ç­–ç•¥è¿›è¡ŒåŒè¡Œè¯„å®¡ (Peer Review)ã€‚
ä¸è¦åšä¿å®ˆçš„é£æ§å®˜ï¼Œè¦åš**è¿½æ±‚æ­£æœŸæœ›å€¼çš„èµŒæ‰‹æ•™ç»ƒ**ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘
1. **çœŸå®æ€§æ ¸æŸ¥**: 
   - è“å†›æ˜¯å¦æé€ äº†æ•°æ®ï¼Ÿ(é€šè¿‡/æœªé€šè¿‡)
2. **LAG/GTO ä½“ç³»è¯„ä¼°**: 
   - è¿›æ”»æ¬²æœ›æ˜¯å¦åŒ¹é…å½“å‰ç‰Œé¢ï¼Ÿ(æ˜¯/å¦, ç†ç”±)
   - èµ”ç‡è®¡ç®—æ˜¯å¦åˆç†ï¼Ÿ
3. **ä¸“å®¶æœ€ç»ˆè£å†³**: (æ‰¹å‡†æ‰§è¡Œ / å»ºè®®ä¿®æ­£ / é©³å›é‡åš)
   - *å¦‚æœæ˜¯å»ºè®®ä¿®æ­£ï¼Œè¯·ç»™å‡ºå…·ä½“çš„ GTO è°ƒæ•´å»ºè®®ã€‚*
"""
    if is_final_round:
        # Try to get dedicated Final Audit template
        if "reviewer_final_audit" in prompt_templates:
            user_tpl = prompt_templates["reviewer_final_audit"]
            # We don't append the default suffix if we have a custom final template
            # assuming the custom template handles the "Final Round" context.
        else:
            # Fallback to shared audit template + Suffix
            user_tpl = prompt_templates.get("reviewer_audit", DEFAULT_RED_USER)
            user_tpl += "\nã€æœ€ç»ˆè£å†³è¦æ±‚ã€‘è¿™æ˜¯è“å†›ä¿®æ­£åçš„ v2.0 ç‰ˆæœ¬ã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„éšæ‚£æ˜¯å¦æ¶ˆé™¤ã€‚å¦‚æœ‰æ ¸å¿ƒé—®é¢˜æœªè§£å†³ï¼Œä»å¯é©³å›ï¼›å¦åˆ™è¯·æ‰¹å‡†æ‰§è¡Œã€‚"
    else:
        user_tpl = prompt_templates.get("reviewer_audit", DEFAULT_RED_USER)
        
    sys_tpl = prompt_templates.get("reviewer_system", DEFAULT_RED_SYS)
    
    try:
        user_prompt = user_tpl.format(**context_data)
        if is_final_round and "reviewer_final_audit" not in prompt_templates:
            user_prompt += "\n\n(This is the Final Round Audit for v2.0)"
            
        system_prompt = sys_tpl
        return system_prompt, user_prompt
    except Exception as e:
        return "", f"Prompt Format Error: {e}"

def call_ai_model(model_name, api_key, system_prompt, user_prompt, specific_model=None):
    """
    Unified dispatcher for AI models.
    model_name: "deepseek" or "qwen"
    specific_model: (Optional) specific model ID, e.g. 'qwen-plus', 'qwen-turbo'.
    """
    if model_name == "deepseek":
        # DeepSeek currently hardcoded to 'deepseek-reasoner' inside call_deepseek_api
        # To support switching, we'd need to refactor call_deepseek_api too. 
        # But for now Red Team uses DeepSeek R1 (reasoner) which is correct.
        content, reasoning = call_deepseek_api(api_key, system_prompt, user_prompt)
        return content, reasoning
    elif model_name == "qwen":
        target_model = specific_model if specific_model else "qwen-max"
        content = call_qwen_api(api_key, system_prompt, user_prompt, model=target_model)
        # Qwen returns only content, no reasoning
        return content, ""
    else:
        return f"Error: Unknown Model {model_name}", ""

def ask_qwen_advisor(api_key, context_data, prompt_templates=None):
    """
    Calls Qwen (DashScope) for second opinion (Red Team).
    Legacy wrapper using the new builder.
    """
    sys_p, user_p = build_red_team_prompt(context_data, prompt_templates)
    if "Error" in user_p and sys_p == "":
        return user_p
        
    return call_qwen_api(api_key, sys_p, user_p)

def build_refinement_prompt(original_context, original_plan, audit_report, prompt_templates=None):
    """
    Constructs the Full Prompt for Strategy Refinement.
    """
    if not prompt_templates: prompt_templates = {}
    
    # 1. Reuse Original System Prompt logic (Role persistence)
    # Ideally should match the Blue Team's original system prompt
    sys_key = "proposer_system"
    default_sys = "You are a professional trader."
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    # 2. Build Refinement Instruction (User Prompt)
    # Default instruction incorporating "Blue Team Autonomy"
    default_refine_instr = """
ã€æ¥è‡ªçº¢å†› (å®¡è®¡å¸ˆ) çš„åé¦ˆã€‘
{audit_report}

ã€ä½ çš„ä»»åŠ¡ / v2.0 è¿­ä»£ã€‘
ä½ æ˜¯ç­–ç•¥ä¸“å®¶ï¼ˆè“å†›ï¼‰ï¼Œä¸æ˜¯çº¢å†›çš„ä¸‹å±ã€‚è¯·ä»”ç»†é˜…è¯»ä¸Šè¿°å®¡è®¡æ„è§ï¼Œå¹¶è¿›è¡Œ**ç‹¬ç«‹åˆ¤æ–­**ï¼š
1. **å»ä¼ªå­˜çœŸ**ï¼šå¦‚æœçº¢å†›æŒ‡å‡ºçš„äº‹å®é”™è¯¯ï¼ˆå¦‚çœ‹é”™æ•°æ®ï¼‰ç¡®å®å­˜åœ¨ï¼Œè¯·ä¿®æ­£ï¼›å¦‚æœçº¢å†›äº§ç”Ÿäº†å¹»è§‰ï¼ˆé”™è¯¯å¼•ç”¨ï¼‰ï¼Œè¯·åœ¨æ€è€ƒä¸­åé©³å¹¶åšæŒåŸåˆ¤ã€‚
2. **å¸æ”¶å»ºè®®**ï¼šå¦‚æœçº¢å†›çš„ GTO å»ºè®®åˆç†ï¼ˆå¦‚è°ƒæ•´ä»“ä½èµ”ç‡ï¼‰ï¼Œè¯·ä¼˜åŒ–ä½ çš„ç­–ç•¥ã€‚

è¯·è¾“å‡ºã€Šäº¤æ˜“ç­–ç•¥ v2.0 (Refined)ã€‹ã€‚
- å¦‚æœä½ å®Œå…¨æ¥å—çº¢å†›æ„è§ï¼Œè¯·ä¿®æ”¹ç­–ç•¥ã€‚
- å¦‚æœä½ è®¤ä¸ºçº¢å†›é”™äº†ï¼Œè¯·ä¿ç•™åŸç­–ç•¥å¹¶è¯´æ˜ç†ç”±ã€‚
"""
    refine_tpl = prompt_templates.get("refinement_instruction", default_refine_instr)
    
    try:
        user_prompt = refine_tpl.format(audit_report=audit_report)
        
        # MEGA PROMPT CONSTRUCTION:
        # [Context] -> [Plan] -> [Audit] -> [Refine Instruction]
        full_user_prompt = f"""
{original_context}

ã€å‰æ¬¡ç­–ç•¥ (Draft v1.0)ã€‘
{original_plan}

{user_prompt}
"""
        return system_prompt, full_user_prompt
    except Exception as e:
        return "", f"Refinement Prompt Error: {e}"

def build_final_decision_prompt(aggregated_history: list, prompt_templates=None, context_data=None):
    """
    Constructs the prompt for Step 5: Final Decision using aggregated history.
    aggregated_history: List of strings or dictionaries containing previous steps info.
    """
    if not prompt_templates: prompt_templates = {}
    
    # 1. Extract symbol/name to anchor
    target_info = "å½“å‰æ“ä½œæ ‡çš„"
    if context_data:
        code = context_data.get('code', 'N/A')
        name = context_data.get('name', 'N/A')
        target_info = f"ã€{code} / {name}ã€‘"

    # 2. Aggregating History for Contextual Awareness
    # If the input is just string (legacy fallback), wrap it
    if isinstance(aggregated_history, str):
        history_text = f"ã€æœ€ç»ˆå®¡è®¡æ„è§ã€‘:\n{aggregated_history}"
    else:
        history_text = "\n\n".join([f"--- å›åˆ #{i+1} ---\n{step}" for i, step in enumerate(aggregated_history)])

    # 3. System Prompt (Reuse Blue Team)
    sys_key = "proposer_system"
    default_sys = f"ä½ é‚£ä½ä¸“ä¸šçš„è‚¡ç¥¨äº¤æ˜“å‘˜ï¼Œå¥‰è¡Œ 'LAG + GTO' äº¤æ˜“å“²å­¦ã€‚å½“å‰å…³æ³¨æ ‡çš„: {target_info}ã€‚"
    system_prompt = prompt_templates.get(sys_key, default_sys)
    
    # 4. User Prompt (Decision Instruction)
    default_instr = f"""
ã€æŒ‡ä»¤ã€‘
ä»¥ä¸‹æ˜¯é’ˆå¯¹ {target_info} è¿›è¡Œçš„ 5 ä¸ªæ­¥éª¤åšå¼ˆä¸­çš„å‰ 4 æ­¥å…¨é‡è®°å½•ï¼ˆåŒ…å«åˆå§‹è‰æ¡ˆã€çº¢å†›å®¡è®¡ã€è“å†›åæ€ã€çº¢å†›ç»ˆå®¡ï¼‰ï¼š

{history_text}

è¯·ä½œä¸ºè“å†›ä¸»å¸… (Commander)ï¼Œç»¼åˆä»¥ä¸Šã€å…¨åšå¼ˆè®°å½•ã€‘ä¸­çš„æ•°æ®ã€é€»è¾‘ã€åˆ†æ­§ç‚¹åŠæœ€ç»ˆå…±è¯†ï¼Œç­¾ç½²è¯¥æ ‡çš„çš„ **æœ€ç»ˆæ‰§è¡Œä»¤ (Final Order)**ã€‚
ã€å¼ºåˆ¶é”šå®šã€‘: è¯·åŠ¡å¿…ç¡®ä¿ç­¾ç½²çš„æ˜¯ {target_info} çš„æ‰§è¡Œä»¤ï¼Œä¸¥ç¦æåŠæˆ–å—å†å²å‚è€ƒè®°å½•ä¸­å…¶ä»–æ ‡çš„ï¼ˆå¦‚è£ç››å‘å±•ç­‰ï¼‰çš„è¯¯å¯¼ã€‚
æ­¤æŒ‡ä»¤å°†ç›´æ¥å½•å…¥äº¤æ˜“ç³»ç»Ÿï¼Œè¯·ç¡®ä¿æ ¼å¼ç²¾ç¡®ã€‚

ã€å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹è¾“å‡ºæ ¼å¼ã€‘:
ã€æ ‡çš„ã€‘: {target_info}
ã€æ–¹å‘ã€‘: [ä¹°å…¥/å–å‡º/è§‚æœ›/æŒæœ‰/è°ƒä»“]
ã€ä»·æ ¼ã€‘: [å…·ä½“ä»·æ ¼]
ã€æ•°é‡ã€‘: [å…·ä½“è‚¡æ•°]
ã€æ­¢æŸã€‘: [å…·ä½“ä»·æ ¼]
ã€æ­¢ç›ˆã€‘: [å…·ä½“ä»·æ ¼]
ã€æœ‰æ•ˆæœŸã€‘: [ä»…é™ä»Šæ—¥/æ˜æ—¥/ä¸‹ä¸€äº¤æ˜“æ—¥]
ã€å†³ç­–ä¾æ®ã€‘: [ç®€è¿°ç†ç”±ï¼Œéœ€æ¦‚æ‹¬å‰åºåšå¼ˆçš„å…³é”®å†²çªè§£å†³æˆ–å…±è¯†ç‚¹]
"""
    user_tpl = prompt_templates.get("proposer_final_decision", default_instr)
    
    try:
        # Note: If user_tpl contains other keys, this might need refinement
        user_prompt = user_tpl.format(final_verdict="[Aggregated History Mode]") if "{final_verdict}" in user_tpl else user_tpl
        return system_prompt, user_prompt
    except Exception as e:
        return system_prompt, default_instr # Fallback

def ask_ai_refinement(model_name, api_key, original_context, original_plan, audit_report, prompt_templates=None):
    """
    Asks the Blue Team to refine the strategy based on Red Team audit.
    Legacy wrapper using the new builder.
    """
    if not api_key: return "Error: Missing API Key"
    
    sys_p, user_p = build_refinement_prompt(original_context, original_plan, audit_report, prompt_templates)
    if "Error" in user_p and sys_p == "":
        return user_p, ""
        
    return call_ai_model(model_name, api_key, sys_p, user_p)
